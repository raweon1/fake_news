{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andre\\anaconda3\\envs\\EngML\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "eids, dfs = utils.get_twitter_from_dir(\"data/Twitter/\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def get_bins(time, bin_size, threshold):\n",
    "    return np.histogram(time, range(0, threshold, bin_size))\n",
    "\n",
    "hist, bins = get_bins(dfs[0][\"timedelta\"], 60*60*12, 60*60*24*90)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 0,  1,  2,  3,  4,  5,  6,  8,  9, 16, 40, 44], dtype=int64)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonzero_bin_idx = hist.nonzero()[0]\n",
    "nonzero_bin_idx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 0,  1,  1,  1,  1,  1,  1,  2,  1,  7, 24,  4], dtype=int64)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.insert(nonzero_bin_idx[1:] - nonzero_bin_idx[:-1], 0, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "array([      0,   43200,   86400,  129600,  172800,  216000,  259200,\n        345600,  388800,  691200, 1728000, 1900800])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins[hist.nonzero()[0]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def add_bins(dfs, bin_size, threshold):\n",
    "    for df in dfs:\n",
    "        df[\"bin\"] = pd.cut(df[\"timedelta\"], range(0, min(int(df[\"timedelta\"].max() + bin_size), threshold), bin_size),\n",
    "                           include_lowest=True, right=False, labels=False)\n",
    "        df[\"timedelta_previous_bin\"] = df[\"bin\"].diff(periods=1) * bin_size\n",
    "        df.at[0, \"timedelta_previous_bin\"] = 0\n",
    "    return dfs\n",
    "dfs = add_bins(dfs, 60*60*12, 60*60*24*90)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "    author_id                 created_at                  id  \\\n0    14294848  2015-11-29 19:14:12+00:00  671044506154893312   \n1  2896866728  2015-11-29 19:16:09+00:00  671044995600613376   \n\n                                                text  timedelta  bin  \\\n0  Walmart has been accused of forcing a Marine t...        0.0    0   \n1  Toys for Nots https://t.co/XGAnfjbRLM https://...      117.0    0   \n\n   timedelta_previous_bin  \n0                     0.0  \n1                     0.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>author_id</th>\n      <th>created_at</th>\n      <th>id</th>\n      <th>text</th>\n      <th>timedelta</th>\n      <th>bin</th>\n      <th>timedelta_previous_bin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>14294848</td>\n      <td>2015-11-29 19:14:12+00:00</td>\n      <td>671044506154893312</td>\n      <td>Walmart has been accused of forcing a Marine t...</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2896866728</td>\n      <td>2015-11-29 19:16:09+00:00</td>\n      <td>671044995600613376</td>\n      <td>Toys for Nots https://t.co/XGAnfjbRLM https://...</td>\n      <td>117.0</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[0][0:2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for i in range(22):\n",
    "    dfs.append(pd.read_csv(f\"data/Twitter/{eids[i]}.csv\").drop([\"Unnamed: 0\"], axis=1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "text = pd.concat([df.text for df in dfs], ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def get_document(texts, tokens_only=False):\n",
    "    for i, text in enumerate(texts):\n",
    "        tokens = gensim.utils.simple_preprocess(text)\n",
    "        if tokens_only:\n",
    "            yield tokens\n",
    "        else:\n",
    "            yield TaggedDocument(tokens, [i])\n",
    "\n",
    "corpus = list(get_document(text))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "model = Doc2Vec(min_count=1, vector_size=100, epochs=20)\n",
    "model.build_vocab(corpus)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "model.train(corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "array([-0.17115064, -0.05264604, -0.02527478, -0.07649111,  0.08997355,\n       -0.02585767,  0.07933673, -0.00032029, -0.03986941, -0.1816277 ,\n        0.04672395,  0.01782438, -0.15455325, -0.04994693,  0.147877  ,\n        0.05942931, -0.17510912, -0.08842883, -0.09098212,  0.12263536,\n       -0.14447547,  0.06814875, -0.07894375, -0.00067529,  0.02474921,\n        0.01541242, -0.1718468 , -0.0121068 , -0.0084113 , -0.08377558,\n        0.00078501, -0.02814474,  0.01598635,  0.19416256, -0.06209496,\n        0.19483422,  0.07029165, -0.16450347, -0.10841694,  0.0283405 ,\n        0.09851441,  0.03884224,  0.03381258, -0.16646175, -0.0633166 ,\n       -0.02029075, -0.09742698, -0.0827698 , -0.03703212, -0.00772073,\n        0.09910872, -0.12129635,  0.15699853, -0.12124533, -0.06546462,\n       -0.00630968, -0.0254756 ,  0.08579536, -0.00882947, -0.00762816,\n        0.03582111,  0.06079223,  0.03300074, -0.1500538 ,  0.01795505,\n       -0.09092139, -0.04543098, -0.0754821 ,  0.01237744, -0.1991638 ,\n       -0.06261256,  0.07330559,  0.05066045,  0.03556779,  0.06266393,\n        0.03073842,  0.02821135, -0.05622221, -0.09907332,  0.13077593,\n        0.09457953, -0.05743042,  0.08745546,  0.02503835, -0.05086665,\n        0.19588071, -0.10143385, -0.02717406, -0.01262817, -0.00074145,\n       -0.07145674,  0.2585131 ,  0.04617283,  0.07105572,  0.02966326,\n       -0.00869683, -0.15511258, -0.00770384,  0.01393382, -0.00641177],\n      dtype=float32)"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.infer_vector(corpus[0][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "model.save(\"models/doc2vec_gensim_100.model\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}